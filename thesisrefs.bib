@article{fcs1,
    author={Tew,A. E. and Guzdial,M.},
    editor={ },
    year={2011},
    title={The FCS1: A language independent assessment of CS1 knowledge},
    booktitle={SIGCSE'11 - Proceedings of the 42nd ACM Technical Symposium on Computer Science Education},
    pages={111-116},
    note={Cited By :49},
    language={English},
}

@article{cs1,
    Address = {(1)Georgia Institute of Technology},
    Author = {Parker, M.C. ( 1 ) and Guzdial, M. ( 1 ) and Engleman, S. ( 2 )},
    Booktitle = {ICER 2016 - Proceedings of the 2016 ACM Conference on International Computing Education Research},
    Number = {ICER 2016 - Proceedings of the 2016 ACM Conference on International Computing Education Research},
    Pages = {93-101},
    Title = {Replication, validation, and use of a language independent CS1 knowledge assessment.},
    Year = {2016},
}

@article{distractor, title={Distractor Efficiency in an Item Pool for a Statistics Classroom Exam: Assessing Its Relation With Item Cognitive Level Classified According to Bloom’s Taxonomy}, volume={9}, DOI={10.3389/fpsyg.2018.01585}, journal={Frontiers in Psychology}, author={Testa, Silvia and Toscano, Anna and Rosato, Rosalba}, year={2018}}

@article{efa2, title={Exploratory factor analysis: A five-step guide for novices}, volume={8}, DOI={10.33151/ajp.8.3.93}, number={3}, journal={Australasian Journal of Paramedicine}, author={Williams, Brett and Onsman, Andrys and Brown, Ted}, year={2010}}

@article{jorian,
    Author = {Jorion, Natalie and Gane, Brian D. and James, Katie and Schroeder, Lianne and DiBello, Louis V. and Pellegrino, James W.},
    ISSN = {10694730},
    Journal = {JOURNAL OF ENGINEERING EDUCATION},
    Keywords = {concept inventories, validity, assessment},
    Number = {4},
    Pages = {454 - 496},
    Title = {An Analytic Framework for Evaluating the Validity of Concept Inventory Claims.},
    Volume = {104},
    Year = {n.d.},
}

@article{jcerp, series={5}, title={Student Misconceptions about Cybersecurity Concepts: Analysis of Think-Aloud Interviews}, volume={2018}, url={Available at: https://digitalcommons.kennesaw.edu/jcerp/vol2018/iss1/5}, number={1}, journal={Journal of Cybersecurity Education, Research and Practice}, author={Thompson, Julia D and Herman, Geoffery L and Scheponik, Travis and Oliva, Linda and Sherman, Alan and Golaszewski, Ennis}, year={2018}, collection={5}}

@article{efa, title={Best Practices in Exploratory Factor Analysis}, DOI={10.4135/9781412995627.d8}, journal={Best Practices in Quantitative Methods}, author={Osborne, Jason W. and Costello, Anna B. and Kellow, J. Thomas}, pages={86–99}, year={Best Practices in Exploratory Factor Analysis}}

@inproceedings{libarkin,
  title={Concept inventories in higher education science},
  author={Libarkin, Julie},
  booktitle={BOSE Conf},
  year={2008}
}






@article{none_of_above,
author = { David   DiBattista  and  Jo-Anne   Sinnige-Egger  and  Glenda   Fortuna },
title = {The “None of the Above” Option in Multiple-Choice Testing: An Experimental Study},
journal = {The Journal of Experimental Education},
volume = {82},
number = {2},
pages = {168-183},
year  = {2014},
publisher = {Routledge},
doi = {10.1080/00220973.2013.795127},

URL = { 
        https://doi.org/10.1080/00220973.2013.795127
    
},
eprint = { 
        https://doi.org/10.1080/00220973.2013.795127
    
}

}




@article{original_delphi, title={Delphi Process A Methodology Used for the Elicitation of Opinions of Experts}, url={https://www.rand.org/pubs/papers/P3925.html}, author={Brown, Bernice B}, year={1968}}

@article{douglas_purzer, title={Validity: Meaning and Relevancy in Assessment for Engineering Education Research}, volume={104}, DOI={10.1002/jee.20070}, number={2}, journal={Journal of Engineering Education}, author={Douglas, Kerrie Anna and Purzer, Şenay}, year={2015}, pages={108–118}}


@article{knowing_what_students_know, title={Knowing What Students Know}, DOI={10.17226/10019}, year={2001}}

@article{diff2, title={Evaluating an electricity and magnetism assessment tool: Brief electricity and magnetism assessment}, volume={2}, DOI={10.1103/physrevstper.2.010105}, number={1}, journal={Physical Review Special Topics - Physics Education Research}, author={Ding, Lin and Chabay, Ruth and Sherwood, Bruce and Beichner, Robert}, year={2006}}

@article{true_score, title={Overview of Classical Test Theory and Item Response Theory for the Quantitative Assessment of Items in Developing Patient-Reported Outcomes Measures}, volume={36}, DOI={10.1016/j.clinthera.2014.04.006}, number={5}, journal={Clinical Therapeutics}, author={Cappelleri, Joseph C. and Lundy, J. Jason and Hays, Ron D.}, year={2014}, pages={648–662}} 


@book{og_ctt, place={Place of publication not identified}, title={A Practitioners Introduction to Equating with Primers on Classical Test Theory and Item Response Theory}, publisher={Distributed by ERIC Clearinghouse}, author={Ryan, Joseph and Brockmann, Frank}, year={2009}}
@article{dlci,
    Abstract = {Concept inventories hold tremendous promise for promoting the rigorous evaluation of teaching methods that might remedy common student misconceptions and promote deep learning. The measurements from concept inventories can be trusted only if the concept inventories are evaluated both by expert feedback and statistical scrutiny (psychometric evaluation). Classical Test Theory and Item Response Theory provide two psychometric frameworks for evaluating the quality of assessment tools. We discuss how these theories can be applied to assessment tools generally and then apply them to the Digital Logic Concept Inventory (DLCI). We demonstrate that the DLCI is sufficiently reliable for research purposes when used in its entirety and as a post-course assessment of students' conceptual understanding of digital logic. The DLCI can also discriminate between students across a wide range of ability levels, providing the most information about weaker students' ability levels.},
    Author = {Herman, Geoffrey L. and Zilles, Craig and Loui, Michael C.},
    Journal = {Computer Science Education},
    Keywords = {Psychometrics; Concept Formation; Measures (Individuals); Teaching Methods; Item Response Theory; Student Evaluation; Educational Assessment; Evaluation Methods; Test Theory; Reliability; Validity; Multiple Choice Tests; Cognitive Processes; Delphi Technique; Student Attitudes; Misconceptions},
    Number = {4},
    Pages = {277 - 303},
    Title = {A Psychometric Evaluation of the Digital Logic Concept Inventory.},
    Volume = {24},
    Year = {2014}
}
@article{cybersecurity_concepts,
    Address = {(1)Cyber Defense Lab, Dept. of Computer Science and Electrical Engineering, University of Maryland, Baltimore County},
    Author = {Scheponik, T. and Sherman, A.T. and DeLatte, D. and Phatak, D. and Oliva, L. and Thompson, J. and Herman, G.L. },
    Booktitle = {Proceedings - Frontiers in Education Conference, FIE},
    Edition = {2016-November},
    Number = {FIE 2016 - Frontiers in Education 2016: The Crossroads of Engineering and Business},
    Journal = {FIE},
    Title = {How students reason about Cybersecurity concepts.},
    Volume = {2016-November},
    Year = {2016}
}
@article{scenarios,
    Abstract = {The authors introduce and explain core concepts of cybersecurity through six engaging practical scenarios. Presented as case studies, the scenarios illustrate how experts may reason through security challenges managing trust and information in the adversarial cyber world. The concepts revolve around adversarial thinking, including understanding the adversary; defining security goals; identifying targets, vulnerabilities, threats, and risks; and devising defenses. They also include dealing with confidentiality, integrity, availability (known as the “CIA triad”), authentication, key management, physical security, and social engineering. The authors hope that these scenarios will inspire students to explore this vital area more deeply. The target audience is anyone who is interested in learningabout cybersecurity, including those with little to no background in cybersecurity. This article will also interest those who teach cybersecurity and are seeking examples and structures for explain},
    Author = {Sherman, Alan T. and DeLatte, David and Neary, Michael and Oliva, Linda and Phatak, Dhananjay and Scheponik, Travis and Herman, Geoffrey L. and Thompson, Julia},
    ISSN = {01611194},
    Journal = {Cryptologia},
    Keywords = {COMPUTER security, COMPUTER crime prevention, computer security, Cybersecurity Assessment Tools (CATS), cybersecurity education, information assurance},
    Number = {4},
    Pages = {337 - 377},
    Title = {Cybersecurity: Exploring core concepts through six scenarios.},
    Volume = {42},
    Year = {2018}
}


@article{delphi,
    ISSN = {0018-9359},
    Journal = {IEEE Transactions on Education, Education, IEEE Transactions on, IEEE Trans. Educ},
    Author = {Geet Parekh and David DeLatte and Geoffrey L Herman and Linda Oliva and Dhananjay Phatak and Travis Scheponik and Alan T. Sherman},
    Keywords = {General Topics for Engineers, Engineering Profession, Computer security, Education, Tools, Cats, Computer science, Engineering profession, Concept inventory, conceptual learning, cybersecurity, cybersecurity assessment tools (CATS), Delphi process, information assurance, student assessment, assessment tools},
    Title = {Identifying Core Concepts of Cybersecurity: Results of Two Delphi Processes.},
    Year = {2018}
}



@article{misconceptions,
    Abstract = {Despite the documented need to train and educate more cybersecurity professionals, we have little rigorous evidence to inform educators on effective ways to engage, educate, or retain cybersecurity students. To begin addressing this gap in our knowledge, we are conducting a series of think-aloud interviews with cybersecurity students to study how students reason about core cybersecurity concepts. We have recruited these students from three diverse institutions: University of Maryland, Baltimore County, Prince George's Community College, and Bowie State University. During these interviews, students grapple with security scenarios designed to probe student understanding of cybersecurity, especially adversarial thinking. We are analyzing student statements using a structured qualitative method, novice-led paired thematic analysis, to document student misconceptions and problematic reasonings. We intend to use these findings to develop Cybersecurity Assessment Tools that can help us asses},
    ISSN = {978-1-5090-1790-4},
    Journal = {2016 IEEE Frontiers in Education Conference (FIE), Frontiers in Education Conference (FIE), 2016 IEEE},
    Keywords = {Computing and Processing, Engineering Profession, Computer security, Interviews, Cognition, Context, Protocols, Computers, cognitive interviews, cybersecurity, Cybersecurity Assessment Tools (CATS), thematic analysis, misconceptions},
    Pages = {1},
    Author = {Travis Scheponik and Alan T. Sherman and David DeLatte and Dhananjay Phatak and Linda Oliva and Julia Thompson and Geoffrey L. Herman},
    Title = {How students reason about Cybersecurity concepts.},
    Year = {2016}
}
@article{workforce,
    Journal = {Frost \& Sullivan},
    Title = {The 2015 (ISC)2 global information security workforce study:},
    Author = {Michael Suby, Frank Dickson},
    Year = {2015}
}

@article{og_cronbach,
author = {J. Cronbach, Lee},
year = {1951},
month = {09},
pages = {297-334},
title = {Coefficient Alpha and Internal Structure of Tests},
volume = {16},
journal = {Psychometrika},
doi = {10.1007/BF02310555}
}
@article{panayiotis,
	author = {Panayiotis Panayides},
	title = {Coefficient Alpha: Interpret With Caution},
	journal = {Europe’s Journal of Psychology},
	volume = {9},
	number = {4},
	year = {2013},
	keywords = {coefficient alpha; reliability; unidimensionality},
	abstract = {Heavy reliance on Cronbach’s alpha has been standard practice in many validation studies. However, there seem to be two misconceptions about the interpretation of alpha. First, alpha is mistakenly considered as an indication of unidimensionality and second, that the higher the value of alpha the better. The aim of this study is to clarify these misconceptions with the use of real data from the educational setting. Results showed that high alpha values can be obtained in multidimensional scales or tests given a sufficient number of items. Therefore, alpha cannot be an indication of unidimensionality. At the same time, after a certain point, higher values of alpha do not necessarily mean higher reliability and better quality scales or tests. In fact very high values of alpha could be an indication of lengthy scales, parallel items or a narrow coverage of the construct under consideration. Researchers are advised to apply caution when reporting alpha.},
	issn = {1841-0413},	url = {https://ejop.psychopen.eu/article/view/653}
}



@book{hackers_wanted, 
    place={Santa Monica, CA}, 
    title={Hackers wanted: an examination of the cybersecurity labor market}, 
    publisher={RAND}, 
    author={Libicki, Martin C. and Senty, David and Pollak, Julia},
    year={2014},
}

@article{ci_progress, 
    title={Progress on concept inventory assessment tools}, DOI={10.1109/fie.2003.1263392}, 
    journal={33rd Annual Frontiers in Education, 2003. FIE 2003.}, author={Evans, D.l. and Gray, G.l. and Krause, S. and Martin, J. and Midkiff, C. and Notaros, B.m. and Pavelich, M. and Rancour, D. and Reed-Rhoads, T. and Steif, P. and et al.}, year={2003}
}

@article{hake, title={Interactive-engagement versus traditional methods: A six-thousand-student survey of mechanics test data for introductory physics courses}, volume={66}, DOI={10.1119/1.18809}, number={1}, journal={American Journal of Physics}, author={Hake, Richard R.}, year={1998}, pages={64–74}}

@article{fci, title={Force concept inventory}, volume={30}, DOI={10.1119/1.2343497}, number={3}, journal={The Physics Teacher}, author={Hestenes, David and Wells, Malcolm and Swackhamer, Gregg}, year={1992}, pages={141–158}}

@book{measurement, place={Prospect Heights, IL}, title={Introduction to Measurement Theory}, publisher={Waveland Press}, author={Allen, Mary J. and Yen, Wendy M.}, year={2002}}

@article{ransomware, title={Cybercriminals Target Hospitals with SamSam Ransomware Attacks}, journal={HealthITSecurity}, publisher={HealthITSecurity}, author={Donovan, Fred}, year={2018}, month={Jun}}

@article{htm, title={The Importance of Cybersecurity Training for HTM Professionals}, volume={50}, DOI={10.2345/0899-8205-50.5.381}, number={5}, journal={Biomedical Instrumentation \& Technology}, author={Wirth, Axel}, year={2016}, pages={381–383}}

@article{litzinger, title={A Cognitive Study of Problem Solving in Statics}, volume={99}, DOI={10.1002/j.2168-9830.2010.tb01067.x}, number={4}, journal={Journal of Engineering Education}, author={Litzinger, Thomas A. and Meter, Peggy Van and Firetto, Carla M. and Passmore, Lucas J. and Masters, Christine B. and Turns, Stephen R. and Gray, Gary L. and Costanzo, Francesco and Zappe, Sarah E.}, year={2010}, pages={337–353}}

@article{evans, title={Progress on concept inventory assessment tools}, DOI={10.1109/fie.2003.1263392}, journal={33rd Annual Frontiers in Education, 2003. FIE 2003.}, author={Evans, D.l. and Gray, G.l. and Krause, S. and Martin, J. and Midkiff, C. and Notaros, B.m. and Pavelich, M. and Rancour, D. and Reed-Rhoads, T. and Steif, P. and et al.}}